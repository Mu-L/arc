# =============================================================================
# Arc Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Server
# -----------------------------------------------------------------------------
[server]
port = 8000

# TLS/HTTPS (disabled by default)
tls_enabled = false
# tls_cert_file = "/etc/letsencrypt/live/example.com/fullchain.pem"
# tls_key_file = "/etc/letsencrypt/live/example.com/privkey.pem"

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
[log]
level = "info"      # debug, info, warn, error, fatal, panic
format = "console"  # json or console

# -----------------------------------------------------------------------------
# Database (DuckDB)
# -----------------------------------------------------------------------------
# Auto-configured based on system resources if not set.
# Override via: ARC_DATABASE_MAX_CONNECTIONS, ARC_DATABASE_MEMORY_LIMIT, ARC_DATABASE_THREAD_COUNT
[database]
# max_connections = 28    # Default: 2x CPU cores
# memory_limit = "8GB"    # Default: ~50% system memory
# thread_count = 14       # Default: CPU cores
enable_wal = true

# -----------------------------------------------------------------------------
# Storage
# -----------------------------------------------------------------------------
[storage]
backend = "local"           # "local" or "s3"
local_path = "./data/arc"

# S3/MinIO (when backend = "s3")
s3_bucket = "arc-test"
s3_region = "us-east-2"
s3_endpoint = ""            # Empty for AWS, set for MinIO
s3_use_ssl = false          # Set true for production
s3_path_style = true        # True for MinIO, false for AWS
# Credentials via env: ARC_STORAGE_S3_ACCESS_KEY, ARC_STORAGE_S3_SECRET_KEY

# -----------------------------------------------------------------------------
# Ingestion
# -----------------------------------------------------------------------------
[ingest]
max_buffer_size = 5000000   # Records before flush (default: 50000)
max_buffer_age_ms = 1000   # Max buffer age before flush

# Sort keys for compression/query performance: "measurement:col1,col2"
# Time column is always appended automatically
sort_keys = []
default_sort_keys = ""

# -----------------------------------------------------------------------------
# Compaction
# -----------------------------------------------------------------------------
[compaction]
enabled = true

# Hourly
hourly_enabled = true
hourly_schedule = "5 * * * *"
hourly_min_age_hours = 0
hourly_min_files = 5

# Daily
daily_enabled = true
daily_schedule = "0 3 * * *"
daily_min_age_hours = 24
daily_min_files = 12

# -----------------------------------------------------------------------------
# Authentication
# -----------------------------------------------------------------------------
[auth]
enabled = true

# -----------------------------------------------------------------------------
# Delete
# -----------------------------------------------------------------------------
[delete]
enabled = true
confirmation_threshold = 10000
max_rows_per_delete = 1000000

# -----------------------------------------------------------------------------
# Retention
# -----------------------------------------------------------------------------
[retention]
enabled = true

# -----------------------------------------------------------------------------
# Continuous Queries
# -----------------------------------------------------------------------------
[continuous_query]
enabled = false

# -----------------------------------------------------------------------------
# MQTT
# -----------------------------------------------------------------------------
[mqtt]
enabled = false

# -----------------------------------------------------------------------------
# Query
# -----------------------------------------------------------------------------
[query]
# S3 file caching (improves CTEs, subqueries, dashboard queries)
enable_s3_cache = false
s3_cache_size = "128MB"
s3_cache_ttl_seconds = 3600

# -----------------------------------------------------------------------------
# Telemetry
# -----------------------------------------------------------------------------
[telemetry]
enabled = true

# -----------------------------------------------------------------------------
# Tiered Storage (Enterprise)
# -----------------------------------------------------------------------------
# Hot tier (local) -> Cold tier (S3/Azure) based on data age
[tiered_storage]
enabled = false
migration_schedule = "0 2 * * *"
migration_max_concurrent = 4
migration_batch_size = 100
default_hot_max_age_days = 0

[tiered_storage.cold]
enabled = false
backend = "s3"              # "s3" or "azure"

# S3/MinIO
s3_bucket = "arc-archive"
s3_region = "us-east-1"
s3_endpoint = "localhost:9000"
s3_access_key = "minioadmin"
s3_secret_key = "minioadmin"
s3_use_ssl = false
s3_path_style = true
s3_storage_class = "GLACIER"

# Azure (when backend = "azure")
azure_container = ""
azure_endpoint = ""
azure_use_managed_identity = false
azure_access_tier = "Archive"

retrieval_mode = "standard"  # standard, expedited, bulk

# -----------------------------------------------------------------------------
# Audit Logging (Enterprise)
# -----------------------------------------------------------------------------
[audit_log]
enabled = false
retention_days = 90
include_reads = false           # Log GET/query requests (high volume)

# Backup & Restore
# -----------------------------------------------------------------------------
[backup]
enabled = true
local_path = "./data/backups"           # Directory for local backups

# Query Management (Enterprise)
# -----------------------------------------------------------------------------
# [query_management]
# enabled = false
# history_size = 100              # Number of completed queries to keep in memory

[wal]
enabled = false