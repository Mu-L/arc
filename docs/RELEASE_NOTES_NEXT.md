# Release Notes - v25.12.1 (Draft)

> **Note**: This file tracks improvements for the upcoming release. Do not commit this file.
>
> **Target Release**: December 2025 (v25.12.1)
> **Fallback**: v25.11.2 if critical bugs are found

## üöÄ New Features

### File-Level Partition Pruning

Arc now includes intelligent partition pruning that dramatically accelerates queries with time filters. Instead of scanning all files using expensive glob patterns, the query engine extracts time ranges from WHERE clauses and generates targeted file paths to read only the partitions that contain relevant data.

**How it works**:
- Automatically extracts time ranges from WHERE clauses (e.g., `time >= '2025-11-10' AND time < '2025-11-16'`)
- Generates specific hour and day partition paths instead of recursive `/**/*.parquet` globs
- Seamlessly handles both hourly and daily compacted files
- Automatically falls back to full scan when no time filter is present
- Filters out non-existent paths for graceful handling of sparse data

**Expected performance improvements**:
- Queries with time filters execute significantly faster
- Reduced file I/O and faster query response times
- Particularly effective for queries over large time ranges with selective filters

**Available in**: Query operations, DELETE operations, continuous queries, and retention policies

Files: [api/partition_pruner.py](api/partition_pruner.py), [api/duckdb_engine.py](api/duckdb_engine.py), [api/delete_routes.py](api/delete_routes.py), [api/continuous_query_routes.py](api/continuous_query_routes.py), [api/retention_routes.py](api/retention_routes.py)

---

### Statistics-Based File Skipping

Arc now leverages Parquet file metadata statistics to skip files that don't match query time ranges. This provides additional query acceleration on top of partition pruning by using lightweight metadata checks to determine which files can be safely skipped without reading their contents.

**How it works**:
- Reads min/max time values from Parquet file metadata
- Skips files where time ranges don't overlap with the query
- Only accesses lightweight metadata - no data downloaded
- Works seamlessly with both regular and compacted files
- All files written by Arc automatically include statistics metadata

**Expected performance improvements**:
- Additional query acceleration when combined with partition pruning
- Reduced file I/O for queries with selective time filters
- Faster query response times across all query patterns

Files: [api/parquet_stats_filter.py](api/parquet_stats_filter.py), [api/partition_pruner.py](api/partition_pruner.py)

---

### Cloud Storage Support for DELETE Operations

DELETE operations now support cloud storage backends including S3, MinIO, GCS, and Ceph. This extends Arc's data deletion capabilities beyond local storage to all supported storage backends.

**How it works**:
- Automatically detects storage backend type (local vs cloud)
- Downloads affected Parquet files for filtering
- Applies WHERE clause filter using DuckDB
- Uploads filtered files back to cloud storage
- Atomically replaces or deletes files based on results

**Supported backends**:
- Local filesystem
- Amazon S3
- MinIO
- Google Cloud Storage (GCS)
- Ceph Object Storage

**DELETE with partition pruning**:
DELETE operations now use the same partition pruning optimization as queries. When time filters are present in WHERE clauses, only relevant partitions are scanned instead of all files.

**Performance impact**:
- Faster file discovery for DELETE operations with time filters
- Reduced cloud storage API calls
- Efficient handling of large datasets across all storage backends

**Example**:
```bash
POST /api/v1/delete
{
  "database": "production",
  "measurement": "logs",
  "where": "time < '2025-01-01' AND severity = 'DEBUG'",
  "dry_run": false,
  "confirm": true
}
```

**Safety features**:
- Dry-run mode for testing
- Confirmation required for large deletes (>10K rows)
- Maximum rows per delete limit (1M rows default)
- SQL injection protection
- Physical deletion (data actually removed)

Files: [api/delete_routes.py](api/delete_routes.py)

---

### Partition Pruning for Continuous Queries

Continuous queries now leverage partition pruning for dramatically faster aggregation execution. When continuous queries include time filters in their SQL, Arc automatically uses targeted partition scanning instead of scanning all files.

**How it works**:
- Continuous query SQL templates use `{start_time}` and `{end_time}` placeholders
- Query engine automatically detects time ranges and applies partition pruning
- Only scans partitions within the aggregation time window
- Works transparently - no changes needed to existing continuous query definitions

**Expected performance improvements**:
- Faster continuous query execution on large datasets
- Reduced I/O when processing time-ranged aggregations
- More efficient resource utilization for scheduled aggregations

**Example**:
```sql
SELECT
  time_bucket(INTERVAL '1 hour', time) as time,
  host,
  AVG(usage_user) as usage_user_avg
FROM cpu
WHERE time >= {start_time} AND time < {end_time}
GROUP BY 1, 2
```

Files: [api/continuous_query_routes.py](api/continuous_query_routes.py)

---

### Partition Pruning for Retention Policies

Retention policies now use partition pruning to efficiently identify and delete old data. Instead of scanning all files, Arc only examines partitions within the retention time range.

**How it works**:
- Generates partition paths from 2015 (or configured start) to retention cutoff date
- Only scans files that could potentially contain old data
- Checks file metadata to confirm all rows are older than cutoff
- Deletes entire files where appropriate (no partial rewrites needed)

**Cloud storage support**:
- Full support for S3, MinIO, GCS, and Ceph retention policies
- Uses partition pruning for efficient cloud file listing
- Minimizes cloud storage API calls
- Downloads only metadata for most files

**Expected performance improvements**:
- Faster retention policy execution on large datasets
- Reduced file scanning for retention checks
- Efficient cloud storage retention enforcement

**Example**:
```bash
POST /api/v1/retention/1/execute
{
  "dry_run": false,
  "confirm": true
}
```

Files: [api/retention_routes.py](api/retention_routes.py)

---

### Automatic `:latest` Docker Tag Updates

When you publish a release on GitHub, Arc now automatically updates the `:latest` Docker tag to point to the newly released version. This eliminates the need for manual Docker tagging after each release.

**How it works**:
- GitHub Actions workflow triggers when you publish a release (not draft)
- Automatically pulls the versioned multi-arch image
- Creates a new `:latest` tag pointing to the release version
- Pushes `:latest` to GitHub Container Registry
- Only applies to stable releases (skips prereleases)

**Benefits**:
- Users can always pull the latest stable version with `docker pull ghcr.io/basekick-labs/arc:latest`
- No manual intervention needed after publishing releases
- Maintains multi-arch support (amd64 + arm64) for `:latest` tag
- Ensures `:latest` only points to reviewed and published releases

**Workflow**: [.github/workflows/release-publish.yml](.github/workflows/release-publish.yml)

---

## üîß Technical Details

### New Files
- `api/partition_pruner.py` - Core partition pruning engine (shared by queries and deletes)
- `api/parquet_stats_filter.py` - Statistics-based file filtering
- `.github/workflows/release-publish.yml` - Automatic `:latest` Docker tag update on release publish

### Modified Files
- `api/duckdb_engine.py` - Integrated partition pruner with query execution
- `api/partition_pruner.py` - Added statistics filtering integration
- `api/delete_routes.py` - Added partition pruning and cloud storage support for DELETE operations
- `api/continuous_query_routes.py` - Integrated partition pruning for continuous query execution
- `api/retention_routes.py` - Added partition pruning and cloud storage support for retention policies

---

## üêõ Bug Fixes

### CTE (Common Table Expression) Support

Fixed a critical bug where CTEs (Common Table Expressions) were incorrectly treated as physical tables, causing "No files found" errors when using `WITH ... AS` clauses in queries.

**What was broken**:
- Queries using CTEs would fail with "No files found that match the pattern"
- Arc's query rewriter attempted to convert CTE names to Parquet file paths
- Example: `WITH campaign AS (...) SELECT * FROM campaign` would try to find `/data/arc/default/campaign/**/*.parquet`

**What's fixed**:
- Query engine now detects and preserves CTE names during SQL rewriting
- Supports multiple CTEs in a single query
- Supports both `WITH cte_name AS (...)` and `WITH RECURSIVE cte_name AS (...)` syntax
- Works with CTEs in FROM and JOIN clauses

**Additionally fixed**:
- Database and table names starting with digits now work correctly (e.g., `3am.logs`)
- JOIN clauses with database.table syntax now properly resolved (e.g., `LEFT JOIN prod.metrics`)

**Example queries that now work**:
```sql
-- CTE with CROSS JOIN
WITH campaign AS (
  SELECT time, event_type
  FROM prod.events
  WHERE event_type = 'marketing_campaign_started'
  LIMIT 1
)
SELECT l.time, l.service, l.level, camp.event_type
FROM campaign camp
CROSS JOIN prod.logs l
WHERE l.time BETWEEN camp.time AND camp.time + INTERVAL '30 minutes';

-- Database names starting with digits
SELECT * FROM 3am.logs WHERE time > NOW() - INTERVAL '1 hour';
```

Files: [api/duckdb_engine.py](api/duckdb_engine.py)

---

### Parallel Compaction Across Measurements

Fixed a performance bottleneck where compaction jobs ran sequentially despite async code and `max_concurrent` setting, limiting throughput to one partition at a time.

**What was broken**:
- Global storage backend lock serialized ALL compaction jobs
- Only 1 partition could compact at a time, regardless of measurement type
- `max_concurrent=2` setting was ineffective - always sequential
- Total compaction time = sum of all individual job durations
- Example: cpu, memory, and logs compaction took 30 seconds (10s each, sequential)

**What's fixed**:
- Per-measurement locking allows different measurements to compact in parallel
- Jobs for same measurement still serialized (prevents storage backend race conditions)
- `max_concurrent` setting now effective - enables true parallelization
- Example: cpu, memory, and logs now compact simultaneously in 10 seconds

**Performance improvements**:
- With 2 measurements + max_concurrent=2: **~2x faster**
- With 4 measurements + max_concurrent=4: **~4x faster**
- With 10 measurements + max_concurrent=10: **~10x faster**
- Actual speedup depends on measurement count and partition distribution

**How it works**:
- Each `(database, measurement)` tuple gets its own lock
- Different measurements (cpu, memory, logs) can compact simultaneously
- Same measurement partitions wait for each other (safe database property access)
- Logs show `‚ö° Parallel compaction: N measurements running concurrently` when active

**Example timeline**:

Before (sequential - 30 seconds):
```
0-10s:  cpu compaction     (memory and logs waiting)
10-20s: memory compaction  (logs waiting)
20-30s: logs compaction
```

After (parallel - 10 seconds):
```
0-10s: cpu + memory + logs all compact simultaneously ‚ö°
```

**Implementation details**:
- `_measurement_locks` dictionary stores per-measurement locks
- `_get_measurement_lock(database, measurement)` creates/retrieves locks on-demand
- Locks are cached for the lifetime of the compaction manager
- Thread-safe lock creation using `_locks_lock` guard

Files: [storage/compaction.py](storage/compaction.py)

---

### Query Result Memory Leak

Fixed a critical memory leak causing gradual memory growth in long-running Arc instances, particularly affecting demo and production deployments with frequent small queries.

**What was broken**:
- Small queries (<1,000 rows) never triggered garbage collection
- Query result objects persisted in memory after responses sent
- DuckDB's internal query result cache accumulated without cleanup
- Memory grew linearly over time (e.g., 20% ‚Üí 28% over 6 hours)
- Particularly affected instances with many small queries (dashboards, demos, monitoring)

**What's fixed**:
- Query results now explicitly deleted after extracting response data
- Large queries (>1,000 rows) trigger immediate garbage collection
- Small queries trigger periodic GC every 100 queries OR every 60 seconds per worker
- Applied to both JSON (`/api/v1/query`) and Arrow (`/api/v1/query/arrow`) endpoints
- Per-worker GC counters prevent overhead while ensuring regular cleanup

**Performance impact**:
- Memory usage now stabilizes with periodic sawtooth pattern (healthy)
- No performance degradation - GC only runs when needed
- Prevents memory exhaustion in long-running deployments
- Particularly beneficial for instances with 1000+ queries per hour

**Memory behavior**:

Before (memory leak):
```
Memory: 20% ‚Üí 21% ‚Üí 23% ‚Üí 25% ‚Üí 27% ‚Üí 28% (continuous growth)
```

After (stable with periodic GC):
```
Memory: 22% ‚Üë 23% ‚Üì 21% ‚Üë 24% ‚Üì 22% ‚Üë 23% ‚Üì (stable plateau)
```

**How it works**:
- All queries: Result objects deleted immediately after response extraction
- Queries >1,000 rows: Immediate `gc.collect()` to free DuckDB memory
- Queries <1,000 rows: GC triggered after 100 queries or 60 seconds (whichever comes first)
- Each worker maintains independent counters (`app.state._query_counter`)
- Time-based fallback ensures GC even with low query rates

**Testing**:
- Verified with 500-query test simulating 6-hour demo workload
- Memory remains stable across extended query sessions
- No impact on query latency or throughput

Files: [api/main.py](api/main.py)

---

### Production-Ready Multi-Worker Configuration

**Added comprehensive production deployment guidance and simplified connection pool for optimal multi-worker performance.**

Arc now includes production-tested configuration patterns and simplified codebase for reliable high-concurrency deployments.

**What's new**:
- **Simplified connection pool** (804 ‚Üí 212 lines, 73.6% reduction):
  - Cleaner codebase with modern context managers
  - Aggressive memory cleanup for stable long-running instances
  - Explicit resource management patterns
- **Production deployment guide** ([docs/PRODUCTION_DEPLOYMENT_GUIDE.md](docs/PRODUCTION_DEPLOYMENT_GUIDE.md)):
  - Configuration formulas by deployment size
  - Memory management best practices
  - Dashboard auto-refresh patterns
  - Monitoring and scaling strategies
- **Multi-worker configuration guide** ([docs/MULTI_WORKER_DUCKDB_CONFIG.md](docs/MULTI_WORKER_DUCKDB_CONFIG.md)):
  - Worker vs thread parallelism explained
  - Configuration by use case
  - Environment variable overrides
- **.env.example updated** with production-ready defaults

**Configuration formula for production**:
```
memory_limit = (System RAM √ó 0.7) / workers
```

**Example configurations**:

Small deployment (32GB RAM, 8 workers):
```toml
[duckdb]
pool_size = 1
threads = 1
memory_limit = "2.8GB"  # Supports 10-20 concurrent queries
```

Large deployment (64GB RAM, 16 workers):
```toml
[duckdb]
pool_size = 1
threads = 1
memory_limit = "2.8GB"  # Supports 20-40 concurrent queries
```

**Key insight**:
> Multi-worker deployments achieve parallelism through worker processes. Configure DuckDB for single-threaded operation per worker for optimal resource utilization.

**Testing**: Validated with high-concurrency workloads including dashboard auto-refresh patterns, burst traffic, and sustained query loads on systems ranging from 16GB to 64GB RAM.

Files: [arc.conf](arc.conf), [.env.example](.env.example), [api/duckdb_pool_simple.py](api/duckdb_pool_simple.py), [api/duckdb_engine.py](api/duckdb_engine.py), [docs/PRODUCTION_DEPLOYMENT_GUIDE.md](docs/PRODUCTION_DEPLOYMENT_GUIDE.md), [docs/MULTI_WORKER_DUCKDB_CONFIG.md](docs/MULTI_WORKER_DUCKDB_CONFIG.md), [docs/CLICKBENCH_CONFIG.md](docs/CLICKBENCH_CONFIG.md)

---

## ‚ö†Ô∏è Breaking Changes

None

---

## üéØ Upgrade Notes

No special upgrade steps required. Changes are backward compatible.

**Recommendations**:
- Consider adding time filters to queries for better performance
- Consider adding time filters to DELETE operations for faster execution
- Continuous queries automatically benefit from partition pruning - no changes needed
- Retention policies now support cloud storage - test with dry_run before execution
- Monitor query performance metrics after upgrade
- Check logs to see which queries, deletes, and retention policies benefit from partition pruning
- If using cloud storage, DELETE and retention operations now work with S3/MinIO/GCS/Ceph
- Test DELETE operations with dry_run=true before executing on production data

---

## üôè Credits

- Implementation: Claude Code + Arc team
- Production testing and validation: Arc users

---

**Target Version**: v25.12.1
**Target Release Date**: December 2025
**Status**: In Development
